# celecx

**C**omputer **E**xperiment **LE**arning **C**urve e**X**trapolation

Tools for active learning on computer experiments, with support for
learning curve extrapolation and progress forecasting.

### [Online Documentation](https://mlr-org.github.io/celecx/)

## Status

Work in progress, nothing in here should be considered stable yet.

## Installation

``` r
# you almost certainly need:
install.packages(c("mlr3learners", "DiceKriging"))

# Install celecx
remotes::install_github("mlr-org/celecx")
```

## Examples

### Gaussian Process, Batch Size 2

Run active learning to explore an unknown function:

``` r
library("celecx")
library("mlr3")
library("mlr3learners")  # for regr.km

# Define objective (unknown function to learn)
objective <- ObjectiveRFun$new(
  fun = function(xs) list(y = sin(xs$x * pi)),
  domain = ps(x = p_dbl(lower = 0, upper = 2)),
  codomain = ps(y = p_dbl(tags = "learn"))
)

# Run active learning
result <- optimize_active(
  objective = objective,
  term_evals = 10L,
  learner = lrn("regr.km", covtype = "matern5_2"),
  se_method = "auto",
  batch_size = 2L,
  aqf_evals = 20L,
  multipoint_method = "greedy"
)

# Access results
result$instance$archive$data  # All evaluated points

xvals <- seq(0, 2, length.out = 100)
yvals.true <- objective$fun(list(x = xvals))$y
yvals.pred <- result$optimizer$surrogate$predict(data.table::data.table(x = xvals))
plot(xvals, yvals.true, col = "red", type = "l", xlab = "x", ylab = "y",
  main = "Active Learning sin(x) with batch_size = 2")
lines(xvals, yvals.pred$mean, col = "blue")
lines(xvals, with(yvals.pred, mean + 1.96 * se), col = "blue", lty = 2)
lines(xvals, with(yvals.pred, mean - 1.96 * se), col = "blue", lty = 2)
text(y ~ x, labels = batch_nr, data = result$instance$archive$data, pos = 1)
```

![](README_files/figure-gfm/example_gp-1.png)

### KNN on a 2D test function

Consider this more complex 2D test function:

``` r
objective <- ObjectiveRFun$new(
  fun = function(xs) {
    bump_a <- exp(-((xs$x1 - 0.3)^2 + (xs$x2 - 0.3)^2) / 0.02)
    bump_b <- 0.7 * exp(-((xs$x1 - 0.8)^2 + (xs$x2 - 0.7)^2) / 0.01)
    list(y = bump_a + bump_b)
  },
  domain = ps(x1 = p_dbl(lower = 0, upper = 1), x2 = p_dbl(lower = 0, upper = 1)),
  codomain = ps(y = p_dbl(tags = "learn"))
)

library("ggplot2")
grid <- data.table::CJ(
  x1 = seq(0, 1, length.out = 100L),
  x2 = seq(0, 1, length.out = 100L)
)
grid[, y := objective$fun(list(x1 = x1, x2 = x2))$y]

ggplot(grid, aes(x1, x2, z = y)) +
  geom_contour_filled() +
  coord_equal()
```

![](README_files/figure-gfm/example_knn-1.png)

Here we use a KNN surrogate model, deliberately chosen because it does
not do its own SE estimation. We therefore give the
`se_method = "bootstrap"` argument, with `se_method_n_bootstrap = 10`
trials (chosen to be small for quick demonstration). We propose
`batch_size = 10` point in each iteration, which are the top 10 from
`aqf_evals = 100` candidate points. We can modify the batch selection
further by influencing the `aqf_optimizer`: It is an `opt("pool")`
optimizer, with its own hyperparameters; here: the sampling method.

``` r
aqf_optimizer <- opt("pool", candidate_generator = candidate_generator_lhs())

result <- optimize_active(
  objective = objective,
  term_evals = 200L,
  learner = lrn("regr.kknn", k = 4L),
  se_method = "bootstrap",
  se_method_n_bootstrap = 10L,
  batch_size = 10L,
  aqf_evals = 100L,
  aqf_optimizer = aqf_optimizer
)

result_data <- result$instance$archive$data[, .(x1, x2, y, batch_nr)]
result_task <- as_task_regr(result_data[, .(x1, x2, y)], target = "y")
kknn_model <- lrn("regr.kknn", k = 3L)$train(result_task)

grid_knn <- data.table::copy(grid)
grid_knn[, y := kknn_model$predict_newdata(grid[, .(x1, x2)])$response]

ggplot(grid_knn, aes(x1, x2, z = y)) +
  geom_contour_filled() +
  geom_point(
    data = result_data,
    mapping = aes(x1, x2, color = batch_nr),
    inherit.aes = FALSE,
    shape = 4,
    size = 1.5,
    stroke = 0.6
  ) +
  scale_color_gradient(
    low = "steelblue",
    high = "firebrick",
    limits = c(1, 6)
  ) +
  coord_equal()
```

![](README_files/figure-gfm/example_knn_opt-1.png)

## License

MIT

# Package index

## Package

- [`celecx`](https://celecx.mlr-org.com/reference/celecx-package.md)
  [`celecx-package`](https://celecx.mlr-org.com/reference/celecx-package.md)
  : celecx: Computer Experiment LEarning Curve eXtrapolation

## Active Learning

Main entry points for running active learning experiments.

- [`optimize_active()`](https://celecx.mlr-org.com/reference/optimize_active.md)
  : Run Active Learning
- [`optimizer_active_learning()`](https://celecx.mlr-org.com/reference/optimizer_active_learning.md)
  : Active Learning Optimizer Factory

## Search Instance

Instance classes for managing active learning runs.

- [`SearchInstance`](https://celecx.mlr-org.com/reference/SearchInstance.md)
  : Search Instance
- [`search_instance()`](https://celecx.mlr-org.com/reference/search_instance.md)
  : Create Search Instance
- [`ContextSearch`](https://celecx.mlr-org.com/reference/ContextSearch.md)
  : Context for Search Instance
- [`search_terminated_error()`](https://celecx.mlr-org.com/reference/search_terminated_error.md)
  : Search Terminated Error

## Objectives

Objective functions for computer experiments.

- [`ObjectiveDataset`](https://celecx.mlr-org.com/reference/ObjectiveDataset.md)
  : Objective Function Based on Pre-evaluated Dataset
- [`ObjectiveLearner`](https://celecx.mlr-org.com/reference/ObjectiveLearner.md)
  : Objective Function Based on a Fitted Learner

## Surrogate Learners

Learners with uncertainty quantification for active learning.

- [`mlr_learners_regr.bootstrap_se`](https://celecx.mlr-org.com/reference/mlr_learners_regr.bootstrap_se.md)
  [`LearnerRegrBootstrapSE`](https://celecx.mlr-org.com/reference/mlr_learners_regr.bootstrap_se.md)
  : Bootstrap Ensemble Learner with SE Prediction
- [`mlr_learners_regr.quantile_se`](https://celecx.mlr-org.com/reference/mlr_learners_regr.quantile_se.md)
  [`LearnerRegrQuantileSE`](https://celecx.mlr-org.com/reference/mlr_learners_regr.quantile_se.md)
  : Quantile Regression Learner with SE Prediction

## Batch Selection

Strategies for selecting multiple points per iteration.

- [`BatchProposer`](https://celecx.mlr-org.com/reference/BatchProposer.md)
  : Batch Proposer
- [`batch_strategies`](https://celecx.mlr-org.com/reference/batch_strategies.md)
  : Batch Selection Strategies
- [`batch_strategy_diversity()`](https://celecx.mlr-org.com/reference/batch_strategy_diversity.md)
  : Diversity Batch Strategy
- [`batch_strategy_greedy()`](https://celecx.mlr-org.com/reference/batch_strategy_greedy.md)
  : Greedy Batch Strategy
- [`batch_strategy_local_penalization()`](https://celecx.mlr-org.com/reference/batch_strategy_local_penalization.md)
  : Local Penalization Batch Strategy

## Candidate Generators

Methods for generating candidate points in pool-based optimization.

- [`candidate_generators`](https://celecx.mlr-org.com/reference/candidate_generators.md)
  : Candidate Point Generators
- [`candidate_generator_grid()`](https://celecx.mlr-org.com/reference/candidate_generator_grid.md)
  : Grid Candidate Generator
- [`candidate_generator_lhs()`](https://celecx.mlr-org.com/reference/candidate_generator_lhs.md)
  : LHS Candidate Generator
- [`candidate_generator_local()`](https://celecx.mlr-org.com/reference/candidate_generator_local.md)
  : Local Candidate Generator
- [`candidate_generator_mixed()`](https://celecx.mlr-org.com/reference/candidate_generator_mixed.md)
  : Mixed Candidate Generator
- [`candidate_generator_random()`](https://celecx.mlr-org.com/reference/candidate_generator_random.md)
  : Random Candidate Generator
- [`candidate_generator_sobol()`](https://celecx.mlr-org.com/reference/candidate_generator_sobol.md)
  : Sobol Candidate Generator

## Optimizers

Acquisition function optimizers.

- [`mlr_optimizers_pool`](https://celecx.mlr-org.com/reference/mlr_optimizers_pool.md)
  [`OptimizerPool`](https://celecx.mlr-org.com/reference/mlr_optimizers_pool.md)
  : Pool-Based Optimizer

## Metrics Tracking

Track and record metrics during active learning.

- [`MetricsTracker`](https://celecx.mlr-org.com/reference/MetricsTracker.md)
  : Metrics Tracker
- [`metrics_tracker()`](https://celecx.mlr-org.com/reference/metrics_tracker.md)
  : Create Metrics Tracker
- [`celecx.metrics_tracker`](https://celecx.mlr-org.com/reference/celecx.metrics_tracker.md)
  [`CallbackMetricsTracker`](https://celecx.mlr-org.com/reference/celecx.metrics_tracker.md)
  : Metrics Tracker Callback
- [`search_metrics`](https://celecx.mlr-org.com/reference/search_metrics.md)
  : Search Metrics
- [`metric_best_y()`](https://celecx.mlr-org.com/reference/metric_best_y.md)
  : Best Y Metric
- [`metric_integrated_variance()`](https://celecx.mlr-org.com/reference/metric_integrated_variance.md)
  : Integrated Variance Metric
- [`metric_max_variance()`](https://celecx.mlr-org.com/reference/metric_max_variance.md)
  : Maximum Variance Metric
- [`metric_mean_variance()`](https://celecx.mlr-org.com/reference/metric_mean_variance.md)
  : Mean Variance Metric
- [`metric_model_mae()`](https://celecx.mlr-org.com/reference/metric_model_mae.md)
  : Model MAE Metric
- [`metric_model_r2()`](https://celecx.mlr-org.com/reference/metric_model_r2.md)
  : Model R-squared Metric
- [`metric_model_rmse()`](https://celecx.mlr-org.com/reference/metric_model_rmse.md)
  : Model RMSE Metric
- [`metric_regret()`](https://celecx.mlr-org.com/reference/metric_regret.md)
  : Regret Metric
- [`metric_simple_regret()`](https://celecx.mlr-org.com/reference/metric_simple_regret.md)
  : Simple Regret Metric
- [`metric_worst_y()`](https://celecx.mlr-org.com/reference/metric_worst_y.md)
  : Worst Y Metric
- [`make_metric()`](https://celecx.mlr-org.com/reference/make_metric.md)
  : Make Metric Function

## Codomain Helpers

Utilities for working with objective codomains.

- [`codomain_goal()`](https://celecx.mlr-org.com/reference/codomain_goal.md)
  : Determine Goal from Codomain
- [`codomain_has_learn()`](https://celecx.mlr-org.com/reference/codomain_has_learn.md)
  : Check if Codomain Has Learning Targets
- [`codomain_has_optimize()`](https://celecx.mlr-org.com/reference/codomain_has_optimize.md)
  : Check if Codomain Has Optimization Targets
- [`codomain_helpers`](https://celecx.mlr-org.com/reference/codomain_helpers.md)
  : Codomain Helpers for Active Learning
- [`codomain_learn_ids()`](https://celecx.mlr-org.com/reference/codomain_learn_ids.md)
  : Get Learning Target IDs
- [`codomain_optimize_ids()`](https://celecx.mlr-org.com/reference/codomain_optimize_ids.md)
  : Get Optimization Target IDs
- [`codomain_target_ids()`](https://celecx.mlr-org.com/reference/codomain_target_ids.md)
  : Get Target IDs from Codomain

## Base Classes

Abstract base classes and utilities.

- [`ConfigurableComponent`](https://celecx.mlr-org.com/reference/ConfigurableComponent.md)
  : ConfigurableComponent
- [`ResultAssignerNull`](https://celecx.mlr-org.com/reference/ResultAssignerNull.md)
  : Null Result Assigner
- [`hash_transform()`](https://celecx.mlr-org.com/reference/hash_transform.md)
  : Create Hash Digest of an Object

